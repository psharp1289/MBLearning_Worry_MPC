{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in and clean data before we start modelling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulsharp/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (0,63,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "#load  in data and just consider columsn of importance for analysis\n",
    "df_task=pd.read_csv('task.csv')\n",
    "df_task_r=df_task[['Participant Public ID','display','forced_choice','Response','image2','test_image1', 'test_image2','test_image1_value', \n",
    "                   'test_image2_value','image_query2', 'image_query1']]\n",
    "df_task_r=df_task_r.replace('response_text_entry','query_internal_probability') \n",
    "\n",
    "# Define best-action dictionary for present design\n",
    "# best action per condition (6 conditions)\n",
    "best_answer_key={'rare_threat_1': [[0, 'Pinecone 1.jpg'], [1, 'Pumpkin 1.jpg']], \n",
    "                 'rare_threat_2': [[0, 'Keyboard 3.jpg'], [1, 'Office supplies 2.jpg']],\n",
    "                 'common_threat_1': [[0, 'Fire hydrant 1.jpg'], [1, 'Fence 2.jpg']],\n",
    "                 'common_threat_2': [[0, 'Bricks 1.jpg'], [1, 'Barrels 1.jpg']],\n",
    "                 'neutral_1': [[0, 'Snow 3.jpg'], [1, 'Skyscraper 1.jpg']],\n",
    "                 'neutral_2': [[0, 'Clean 1.jpg'], [1, 'Cotton swabs 3.jpg']]}\n",
    "\n",
    "#best answers per condition: lists\n",
    "rt1=[]\n",
    "rt2=[]\n",
    "ct1=[]\n",
    "ct2=[]\n",
    "n1=[]\n",
    "n2=[]\n",
    "\n",
    "tally=0\n",
    "invalid_scores={'NaN'}\n",
    "counter=0\n",
    "conditions=[]\n",
    "start_new_test_set=0\n",
    "start_new_subject=0\n",
    "best_action_tally=0\n",
    "condition_counter=0\n",
    "sub_counter=0\n",
    "current_subject=1\n",
    "\n",
    "#subject specific data\n",
    "rt_sub=[]\n",
    "ct_sub=[]\n",
    "neut_sub=[]\n",
    "current_choice_data=[]\n",
    "choice_data_3d=np.zeros((13,3,40)) #to be populated below\n",
    "\n",
    "for row,data in df_task_r.iterrows():\n",
    "    \n",
    "    if str(df_task_r['display'][row]).startswith('test'):\n",
    "        \n",
    "        if counter==0:\n",
    "            conditions.append(df_task_r['display'][row][5:])\n",
    "            condition_info=best_answer_key[conditions[counter]]\n",
    "            new_condition=0\n",
    "            counter+=1\n",
    "            \n",
    "\n",
    "        elif df_task_r['display'][row][5:]!=conditions[counter-1]:\n",
    "                    conditions.append(df_task_r['display'][row][5:])\n",
    "                    condition_info=best_answer_key[conditions[counter]]\n",
    "                    if conditions[counter-1]=='rare_threat_1':\n",
    "                        rt1.append(best_action_tally)\n",
    "                        rt_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='rare_threat_2':\n",
    "                        rt2.append(best_action_tally)\n",
    "                        rt_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='common_threat_1':\n",
    "                        ct1.append(best_action_tally)\n",
    "                        ct_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='common_threat_2':\n",
    "                        ct2.append(best_action_tally)\n",
    "                        ct_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='neutral_1':\n",
    "                        n1.append(best_action_tally)\n",
    "                        neut_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='neutral_2':\n",
    "                        n2.append(best_action_tally)\n",
    "                        neut_sub.append(current_choice_data)\n",
    "                    counter+=1\n",
    "                    best_action_tally=0\n",
    "                    current_choice_data=[]\n",
    "                    condition_counter+=1\n",
    "                    #after 6 blocks, new subject\n",
    "                    if condition_counter>5:\n",
    "                        current_subject+=1\n",
    "                        neut_sub=neut_sub[0]+neut_sub[1]\n",
    "                        if len(neut_sub)<40:\n",
    "                            neut_sub=[int(x) for x in neut_sub+np.zeros(40-len(neut_sub)).tolist()]\n",
    "             \n",
    "                            \n",
    "                        rt_sub=rt_sub[0]+rt_sub[1]\n",
    "                        if len(rt_sub)<40:\n",
    "                            rt_sub=[int(x) for x in rt_sub+np.zeros(40-len(rt_sub)).tolist()]\n",
    "                      \n",
    "                        ct_sub=ct_sub[0]+ct_sub[1]\n",
    "                        if len(ct_sub)<40:\n",
    "                            ct_sub=[int(x) for x in ct_sub+np.zeros(40-len(ct_sub)).tolist()]\n",
    "                        \n",
    "                        choice_data_3d[sub_counter,0]=neut_sub\n",
    "                        choice_data_3d[sub_counter,1]=ct_sub\n",
    "                        choice_data_3d[sub_counter,2]=rt_sub\n",
    "                        sub_counter+=1                                               \n",
    "                        condition_counter=0\n",
    "                        rt_sub=[]\n",
    "                        ct_sub=[]\n",
    "                        neut_sub=[]\n",
    "        \n",
    "        else:\n",
    "            new_condition=0\n",
    "                    \n",
    "        #Get values and convert from strings to floating point\n",
    "        value1=df_task_r['test_image1_value'][row]\n",
    "        if \"p\" in value1:\n",
    "            value1=float(value1[0:2])*0.01\n",
    "        else:\n",
    "            value1=float(value1[1])\n",
    "        value2=df_task_r['test_image2_value'][row]\n",
    "        if \"p\" in value2:\n",
    "            value2=float(value2[0:2])*0.01\n",
    "        else:\n",
    "            value2=float(value2[1])\n",
    "        \n",
    "        if value1>value2:\n",
    "            best_option=df_task_r['test_image1'][row]\n",
    "        else:\n",
    "            best_option=df_task_r['test_image2'][row]\n",
    "        \n",
    "            \n",
    "        #get response and convert to integer\n",
    "        try:\n",
    "            current_response=int(df_task_r['Response'][row])\n",
    "        except:\n",
    "            current_response='missing'\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        # determine if participant made best choice\n",
    "        for info_total in condition_info:\n",
    "            for info in info_total:\n",
    "                if best_option == str(info):\n",
    "                    best_action=info_total[0]\n",
    "\n",
    "        #for last subject only that doesn't meet the condition above for indexing     \n",
    "        if row==17254:\n",
    "            ct2.append(best_action_tally)\n",
    "            ct_sub.append(current_choice_data)\n",
    "            neut_sub=neut_sub[0]+neut_sub[1]\n",
    "            if len(neut_sub)<40:\n",
    "                neut_sub=[int(x) for x in neut_sub+np.zeros(40-len(neut_sub)).tolist()]\n",
    "\n",
    "\n",
    "            rt_sub=rt_sub[0]+rt_sub[1]\n",
    "            if len(rt_sub)<40:\n",
    "                rt_sub=[int(x) for x in rt_sub+np.zeros(40-len(rt_sub)).tolist()]\n",
    "\n",
    "            ct_sub=ct_sub[0]+ct_sub[1]\n",
    "            if len(ct_sub)<40:\n",
    "                ct_sub=[int(x) for x in ct_sub+np.zeros(40-len(ct_sub)).tolist()]\n",
    "\n",
    "            choice_data_3d[sub_counter,0]=neut_sub\n",
    "            choice_data_3d[sub_counter,1]=ct_sub\n",
    "            choice_data_3d[sub_counter,2]=rt_sub\n",
    "            sub_counter+=1                                               \n",
    "            condition_counter=0\n",
    "            rt_sub=[]\n",
    "            ct_sub=[]\n",
    "            neut_sub=[]\n",
    "\n",
    "        else:\n",
    "            if current_response==best_action:\n",
    "                best_action_tally+=1\n",
    "                current_choice_data.append(1.0)\n",
    "            elif current_response=='missing':\n",
    "                x='missing'\n",
    "            else:\n",
    "                current_choice_data.append(0.0)\n",
    "                \n",
    "\n",
    "#convert to numpy arrays    \n",
    "rt1=np.array(rt1)\n",
    "rt2=np.array(rt2)\n",
    "ct1=np.array(ct1)\n",
    "ct2=np.array(ct2)\n",
    "n1=np.array(n1)\n",
    "n2=np.array(n2)\n",
    "\n",
    "choice_data_3d = choice_data_3d.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Modelling pilot data hierarchically: explaining choice data\n",
    "\n",
    "In the present experiment, participants chose an action to obtain a reward based off a latent transition matrix they've presumably learned. The hypothesis is that this transition matrix is altered due to experimentally-manipulated features (valence of emotional distractors during learning) and person-specific factors that are not manipulated (level of chronic worry). \n",
    "\n",
    "We can conceive of the generative model of my data in the following way. We'll start from the bottom up. Each individual's decision is either a 1 or 0 (did they select the best-available option or not). The best-available option is the action that maximizes the EV according to a greedy policy (which is normative here given that learning has terminated once decision-making begins; that is, if I've learned I have a 60% chance pressing X will get me to the highest reward, and Y will get me there 40% of the time, I should always choose X). \n",
    "\n",
    "The $\\theta$ parameter determines a subjects' choice. If their bias is 0, it is an index that they're always choosing the worst action. If the bias is 1, they're maximizing performance. \n",
    "\n",
    "We use a Bernoulli likelihood to define the **subject-specific** data-generating process to explain their choice data:\n",
    "\n",
    "$Choice_{i,t}$ $\\sim$ Bernoulli$(\\theta_{i,k})$ Indices: i=subjects, t=trials, k=condition, where k(1) = neutral, k(2) = positive and k(3) = negative. \n",
    "\n",
    "These decicision biases, $\\theta$, vary by subject and condition. Each subject has a parameter that encodes the effect of each experimental condition $\\gamma_{k}$. A logistic link function is necessary to take a set spanning all values to the 0 to 1 range in order to be appropriate for the Bernoulli likelihood.\n",
    "\n",
    "$\\theta_{i,k}\\,= \\begin{cases}\n",
    "    \\text{logistic}\\, (\\gamma_{i,1}),& \\text{if } k=1\\\\\n",
    "    \\text{logistic}\\,(\\gamma_{i,2}),& \\text{if } k=2\\\\\n",
    "    \\text{logistic}\\,(\\gamma_{i,3}),& \\text{if } k=3\\\\\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "$\\gamma_{1}$, $\\gamma_{2}$, and $\\gamma_{3}$ represent the biases for **each condition** per subject, where each is drawn from **group-level distribution over condition effects**:\n",
    "\n",
    "$\\gamma_{i,1}$ $\\sim \\mathcal{N}(\\mu_{1},\\sigma_{1})$\n",
    "\n",
    "$\\gamma_{i,2}$ $\\sim \\mathcal{N}(\\mu_{2},\\sigma_{2})$\n",
    "\n",
    "$\\gamma_{i,3}$ $\\sim \\mathcal{N}(\\mu_{3},\\sigma_{3})$\n",
    "\n",
    "Because we do not know *a priori* what the population-level distribution over each effect should be, we also need a prior distribution on these parameters. Priors over **experimental effects** at the population level:\n",
    "\n",
    "Mean Prior:\n",
    "$\\mathcal{N}(\\mathcal{M_{condition}},\\sigma_{condition})$\n",
    "Variance Prior:\n",
    "$\\mathcal{Gamma}(\\mathcal{S_{condition}},\\mathcal{K_{condition}})$\n",
    "\n",
    "The posterior joint distribution one is trying to estimate is: $p(\\gamma_{1,1}...\\gamma_{subject_i,condition_k},\\mu_{k},\\sigma_{k}|data)$. Thus we must estimate $(i \\cdot k) + 6_{groupLevel}$ parameters, which for the present dataset, is a 45-dimensional distribution.We use pyStan to fit the model to the data below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build hierarchical model in pyStan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_26e96afb883e887181defe52649573b7 NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_26e96afb883e887181defe52649573b7.\n",
      "4 chains, each with iter=4000; warmup=2000; thin=1; \n",
      "post-warmup draws per chain=2000, total post-warmup draws=8000.\n",
      "\n",
      "                     mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu_neutral           3.93    0.02    1.3   1.76   3.05   3.78   4.65   6.96   2788    1.0\n",
      "mu_positive           1.9    0.02   1.35  -0.62   1.01   1.85   2.74   4.71   7259    1.0\n",
      "mu_negative          1.46    0.01   0.92  -0.29   0.86   1.43   2.03   3.37   7151    1.0\n",
      "sigma_neutral        3.58    0.02   1.01   2.08   2.87   3.42   4.11   6.05   2089    1.0\n",
      "sigma_positive       4.36    0.02   1.02   2.77   3.63   4.23   4.94   6.76   3855    1.0\n",
      "sigma_negative       3.11    0.01   0.72    2.0    2.6    3.0   3.52   4.76   4332    1.0\n",
      "gamma_neutral[1]     0.24  2.9e-3   0.32  -0.37   0.02   0.24   0.46   0.89  12233    1.0\n",
      "gamma_neutral[2]     6.82    0.05   2.66   3.16   4.88   6.28   8.18  13.35   2988    1.0\n",
      "gamma_neutral[3]    -0.27  3.0e-3   0.33  -0.91  -0.49  -0.27  -0.05   0.36  12122    1.0\n",
      "gamma_neutral[4]     6.82    0.05   2.71    3.2   4.89   6.28   8.17  13.42   3204    1.0\n",
      "gamma_neutral[5]    -0.27  3.1e-3   0.33  -0.92  -0.48  -0.26  -0.05   0.36  11364    1.0\n",
      "gamma_neutral[6]     6.82    0.05    2.7   3.21   4.92   6.25   8.19  13.57   3042    1.0\n",
      "gamma_neutral[7]     6.82    0.04   2.68   3.18    4.9    6.3   8.16  13.55   3711    1.0\n",
      "gamma_neutral[8]     0.03  3.2e-3   0.33  -0.61  -0.18   0.03   0.24   0.68  10400    1.0\n",
      "gamma_neutral[9]     6.85    0.05    2.7   3.22   4.93    6.3   8.19  13.59   2833    1.0\n",
      "gamma_neutral[10]    6.82    0.05   2.66   3.21   4.95   6.27   8.14   13.5   2900    1.0\n",
      "gamma_neutral[11]   -0.07  3.0e-3   0.32  -0.71  -0.29  -0.07   0.14   0.56  11665    1.0\n",
      "gamma_neutral[12]    6.81    0.05   2.63   3.18   4.96   6.29   8.11  13.33   3038    1.0\n",
      "gamma_neutral[13]    4.11    0.01   1.15   2.31    3.3   3.95   4.75   6.77   6976    1.0\n",
      "gamma_positive[1]   -1.58  4.1e-3   0.43  -2.45  -1.84  -1.56  -1.29  -0.78  10679    1.0\n",
      "gamma_positive[2]    6.78    0.05   2.79   3.14   4.83   6.13    8.1  13.86   3406    1.0\n",
      "gamma_positive[3]   -5.78    0.03   2.22 -11.45  -6.86  -5.31  -4.21  -2.81   4546    1.0\n",
      "gamma_positive[4]    6.72    0.04   2.62   3.14   4.82   6.21   8.03   13.2   4397    1.0\n",
      "gamma_positive[5]   -0.73  3.1e-3   0.34  -1.43  -0.96  -0.72   -0.5  -0.06  12008    1.0\n",
      "gamma_positive[6]    1.14  3.6e-3   0.37   0.45   0.89   1.13   1.38   1.91  10739    1.0\n",
      "gamma_positive[7]    3.99    0.01   1.12   2.27   3.19   3.83    4.6   6.67   5882    1.0\n",
      "gamma_positive[8]   -3.74    0.01   1.01  -6.11  -4.31  -3.61  -3.02  -2.14   6612    1.0\n",
      "gamma_positive[9]    6.78    0.04   2.75    3.1   4.79   6.21   8.15  13.57   4279    1.0\n",
      "gamma_positive[10]   4.01    0.01   1.14   2.22   3.22   3.85   4.63   6.66   6608    1.0\n",
      "gamma_positive[11]  -3.01  7.9e-3   0.72  -4.59  -3.46  -2.95  -2.49  -1.78   8377    1.0\n",
      "gamma_positive[12]   6.74    0.04   2.67   3.14   4.78   6.23   8.12   13.4   4626    1.0\n",
      "gamma_positive[13]   3.99    0.01   1.11   2.24   3.21   3.85   4.61   6.64   7213    1.0\n",
      "gamma_negative[1]    0.22  3.1e-3   0.33  -0.42 4.3e-3   0.22   0.44   0.88  11334    1.0\n",
      "gamma_negative[2]    5.49    0.03   1.88   2.82   4.17   5.13   6.44  10.14   4330    1.0\n",
      "gamma_negative[3]   -2.19  5.4e-3   0.55  -3.38  -2.53  -2.15  -1.81  -1.23  10014    1.0\n",
      "gamma_negative[4]    0.12  3.0e-3   0.32  -0.51   -0.1   0.12   0.34   0.76  11625    1.0\n",
      "gamma_negative[5]   -0.09  3.1e-3   0.32  -0.71   -0.3  -0.08   0.12   0.53  10456    1.0\n",
      "gamma_negative[6]    2.28  5.6e-3   0.55   1.31   1.89   2.24   2.62   3.48   9374    1.0\n",
      "gamma_negative[7]    2.61  6.5e-3   0.62   1.56   2.17   2.56   2.99   3.98   9124    1.0\n",
      "gamma_negative[8]   -2.91  7.5e-3   0.71  -4.45  -3.33  -2.83  -2.42   -1.7   9029    1.0\n",
      "gamma_negative[9]    5.53    0.03   1.89   2.85   4.18   5.19   6.51  10.15   4326    1.0\n",
      "gamma_negative[10]   1.59  3.8e-3   0.43   0.82    1.3   1.57   1.87   2.48  12317    1.0\n",
      "gamma_negative[11]   -2.9  7.6e-3    0.7  -4.45  -3.33  -2.85   -2.4  -1.72   8619    1.0\n",
      "gamma_negative[12]   5.54    0.03   1.91   2.85   4.18   5.21   6.47  10.37   4175    1.0\n",
      "gamma_negative[13]   3.78    0.01   1.01   2.19   3.08   3.66   4.36   6.11   7300    1.0\n",
      "theta_neutral[1]     0.56  7.0e-4   0.08   0.41   0.51   0.56   0.61   0.71  12257    1.0\n",
      "theta_neutral[2]     0.99  1.2e-4   0.01   0.96   0.99    1.0    1.0    1.0   9176    1.0\n",
      "theta_neutral[3]     0.43  7.1e-4   0.08   0.29   0.38   0.43   0.49   0.59  12137    1.0\n",
      "theta_neutral[4]     0.99  1.2e-4   0.01   0.96   0.99    1.0    1.0    1.0   8509    1.0\n",
      "theta_neutral[5]     0.43  7.3e-4   0.08   0.28   0.38   0.43   0.49   0.59  11441    1.0\n",
      "theta_neutral[6]     0.99  1.3e-4   0.01   0.96   0.99    1.0    1.0    1.0   8349    1.0\n",
      "theta_neutral[7]     0.99  1.3e-4   0.01   0.96   0.99    1.0    1.0    1.0   8638    1.0\n",
      "theta_neutral[8]     0.51  7.8e-4   0.08   0.35   0.45   0.51   0.56   0.66  10421    1.0\n",
      "theta_neutral[9]     0.99  1.2e-4   0.01   0.96   0.99    1.0    1.0    1.0   8140    1.0\n",
      "theta_neutral[10]    0.99  1.3e-4   0.01   0.96   0.99    1.0    1.0    1.0   7524    1.0\n",
      "theta_neutral[11]    0.48  7.2e-4   0.08   0.33   0.43   0.48   0.54   0.64  11714    1.0\n",
      "theta_neutral[12]    0.99  1.2e-4   0.01   0.96   0.99    1.0    1.0    1.0   8295    1.0\n",
      "theta_neutral[13]    0.97  2.2e-4   0.02   0.91   0.96   0.98   0.99    1.0  11527    1.0\n",
      "theta_positive[1]    0.18  5.4e-4   0.06   0.08   0.14   0.17   0.22   0.31  12140    1.0\n",
      "theta_positive[2]    0.99  1.2e-4   0.01   0.96   0.99    1.0    1.0    1.0   9518    1.0\n",
      "theta_positive[3]    0.01  1.6e-4   0.02 1.1e-5 1.0e-3 4.9e-3   0.01   0.06  10557    1.0\n",
      "theta_positive[4]    0.99  1.2e-4   0.01   0.96   0.99    1.0    1.0    1.0   9823    1.0\n",
      "theta_positive[5]    0.33  6.6e-4   0.07   0.19   0.28   0.33   0.38   0.48  12306    1.0\n",
      "theta_positive[6]    0.75  6.3e-4   0.07   0.61   0.71   0.76    0.8   0.87  11242    1.0\n",
      "theta_positive[7]    0.97  2.3e-4   0.02   0.91   0.96   0.98   0.99    1.0  11603    1.0\n",
      "theta_positive[8]    0.03  2.5e-4   0.03 2.2e-3   0.01   0.03   0.05   0.11  12481    1.0\n",
      "theta_positive[9]    0.99  1.2e-4   0.01   0.96   0.99    1.0    1.0    1.0  10532    1.0\n",
      "theta_positive[10]   0.97  2.3e-4   0.03    0.9   0.96   0.98   0.99    1.0  12390    1.0\n",
      "theta_positive[11]   0.06  3.3e-4   0.04   0.01   0.03   0.05   0.08   0.14  11360    1.0\n",
      "theta_positive[12]   0.99  1.3e-4   0.01   0.96   0.99    1.0    1.0    1.0   9307    1.0\n",
      "theta_positive[13]   0.97  2.4e-4   0.03    0.9   0.96   0.98   0.99    1.0  11292    1.0\n",
      "theta_negative[1]    0.55  7.3e-4   0.08    0.4    0.5   0.56   0.61   0.71  11479    1.0\n",
      "theta_negative[2]    0.99  1.6e-4   0.02   0.94   0.98   0.99    1.0    1.0   9702    1.0\n",
      "theta_negative[3]    0.11  4.6e-4   0.05   0.03   0.07    0.1   0.14   0.23  12148    1.0\n",
      "theta_negative[4]    0.53  7.2e-4   0.08   0.37   0.48   0.53   0.58   0.68  11678    1.0\n",
      "theta_negative[5]    0.48  7.5e-4   0.08   0.33   0.43   0.48   0.53   0.63  10515    1.0\n",
      "theta_negative[6]     0.9  4.3e-4   0.05   0.79   0.87    0.9   0.93   0.97  11857    1.0\n",
      "theta_negative[7]    0.92  3.7e-4   0.04   0.83    0.9   0.93   0.95   0.98  12028    1.0\n",
      "theta_negative[8]    0.06  3.4e-4   0.04   0.01   0.03   0.06   0.08   0.15  12018    1.0\n",
      "theta_negative[9]    0.99  1.5e-4   0.02   0.95   0.98   0.99    1.0    1.0  10452    1.0\n",
      "theta_negative[10]   0.82  5.2e-4   0.06   0.69   0.79   0.83   0.87   0.92  12846    1.0\n",
      "theta_negative[11]   0.06  3.4e-4   0.04   0.01   0.03   0.05   0.08   0.15  12071    1.0\n",
      "theta_negative[12]   0.99  1.5e-4   0.02   0.95   0.98   0.99    1.0    1.0  10300    1.0\n",
      "theta_negative[13]   0.97  2.6e-4   0.03    0.9   0.96   0.97   0.99    1.0  10501    1.0\n",
      "lp__               -490.5    0.13   5.83 -503.2 -494.3 -490.1 -486.4 -480.3   2057    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Sep 21 14:03:43 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "from pystan import StanModel\n",
    "\n",
    "\n",
    "model_input='''\n",
    "data {\n",
    "    int<lower=0> N;      // # of subjects\n",
    "    int N_cond;\n",
    "    int T_max;  // max # of trials across subjects\n",
    "    int Choice[N, N_cond, T_max]; // Choices for each subject, condition, and trial\n",
    "}\n",
    "\n",
    "parameters {  \n",
    " \n",
    "  // Parameters for group-level parameters\n",
    "  real mu_neutral;\n",
    "  real mu_positive;\n",
    "  real mu_negative;\n",
    "  \n",
    "  real<lower=0> sigma_neutral;\n",
    "  real<lower=0> sigma_positive;  \n",
    "  real<lower=0> sigma_negative;\n",
    "  \n",
    "  \n",
    "  // Individual-level parameters\n",
    "  real gamma_neutral[N];\n",
    "  real gamma_positive[N];\n",
    "  real gamma_negative[N];\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  vector[N] theta_neutral;\n",
    "  vector[N] theta_positive;\n",
    "  vector[N] theta_negative;\n",
    "\n",
    "  // For all subjects, incorporate baseline and experimental effect, \n",
    "  // then convert to 0-1 scale via logistic function. \n",
    "  \n",
    "  for (i in 1:N) {\n",
    "    theta_neutral[i] = inv_logit(gamma_neutral[i]);\n",
    "    theta_positive[i] = inv_logit(gamma_positive[i]);\n",
    "    theta_negative[i] = inv_logit(gamma_negative[i]);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  // Priors on group-level effects\n",
    "  mu_neutral   ~ normal(0,10);\n",
    "  mu_positive ~ normal(0,10);\n",
    "  mu_negative ~ normal(0,10);\n",
    "  \n",
    "  sigma_neutral ~ gamma(1,1);\n",
    "  sigma_positive ~ gamma(1,1);\n",
    "  sigma_negative ~ gamma(1,1);\n",
    "\n",
    "  \n",
    "  // Priors on individual parameters\n",
    "  gamma_neutral ~ normal(mu_neutral,sigma_neutral);\n",
    "  gamma_positive ~ normal(mu_positive,sigma_positive);\n",
    "  gamma_negative ~ normal(mu_negative,sigma_negative);\n",
    "\n",
    "    \n",
    "  // Generate data for each subject via Bernoulli likelihood\n",
    "  for (i in 1:N) {\n",
    "    // Neutral condition choices\n",
    "    Choice[i,1,:] ~ bernoulli(theta_neutral[i]);\n",
    "    // Positive condition choices\n",
    "    Choice[i,2,:] ~ bernoulli(theta_positive[i]);\n",
    "    // Negative condition choices\n",
    "    Choice[i,3,:] ~ bernoulli(theta_negative[i]);    \n",
    "  }\n",
    "}\n",
    "\n",
    "'''\n",
    "data_input = {'N': 13, #subjects\n",
    "                     'N_cond': 3, # conditions\n",
    "                     'T_max': 40, # trials per condition\n",
    "                     'Choice':choice_data_3d #choice data in a 3d Vector\n",
    "                    }\n",
    "\n",
    "controls={}\n",
    "controls['adapt_delta']=0.8\n",
    "\n",
    "model_fit = StanModel(model_code=model_input)\n",
    "fit = model_fit.sampling(data=data_input,iter=4000,control=controls)\n",
    "print(fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
