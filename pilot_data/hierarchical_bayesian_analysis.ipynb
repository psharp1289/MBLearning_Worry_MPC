{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in and clean data before we start modelling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/paulsharp/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (0,63,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1 1 ... 0 0 0]\n",
      "  [1 0 0 ... 0 1 0]\n",
      "  [1 1 1 ... 1 0 0]]\n",
      "\n",
      " [[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[0 0 0 ... 1 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 1 1 1]\n",
      "  [0 0 0 ... 0 0 1]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [0 1 1 ... 1 1 1]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "#load  in data and just consider columsn of importance for analysis\n",
    "df_task=pd.read_csv('task.csv')\n",
    "df_task_r=df_task[['Participant Public ID','display','forced_choice','Response','image2','test_image1', 'test_image2','test_image1_value', \n",
    "                   'test_image2_value','image_query2', 'image_query1']]\n",
    "df_task_r=df_task_r.replace('response_text_entry','query_internal_probability') \n",
    "\n",
    "# Define best-action dictionary for present design\n",
    "# best action per condition (6 conditions)\n",
    "best_answer_key={'rare_threat_1': [[0, 'Pinecone 1.jpg'], [1, 'Pumpkin 1.jpg']], \n",
    "                 'rare_threat_2': [[0, 'Keyboard 3.jpg'], [1, 'Office supplies 2.jpg']],\n",
    "                 'common_threat_1': [[0, 'Fire hydrant 1.jpg'], [1, 'Fence 2.jpg']],\n",
    "                 'common_threat_2': [[0, 'Bricks 1.jpg'], [1, 'Barrels 1.jpg']],\n",
    "                 'neutral_1': [[0, 'Snow 3.jpg'], [1, 'Skyscraper 1.jpg']],\n",
    "                 'neutral_2': [[0, 'Clean 1.jpg'], [1, 'Cotton swabs 3.jpg']]}\n",
    "\n",
    "#best answers per condition: lists\n",
    "rt1=[]\n",
    "rt2=[]\n",
    "ct1=[]\n",
    "ct2=[]\n",
    "n1=[]\n",
    "n2=[]\n",
    "\n",
    "tally=0\n",
    "invalid_scores={'NaN'}\n",
    "counter=0\n",
    "conditions=[]\n",
    "start_new_test_set=0\n",
    "start_new_subject=0\n",
    "best_action_tally=0\n",
    "condition_counter=0\n",
    "sub_counter=0\n",
    "current_subject=1\n",
    "\n",
    "#subject specific data\n",
    "rt_sub=[]\n",
    "ct_sub=[]\n",
    "neut_sub=[]\n",
    "current_choice_data=[]\n",
    "choice_data_3d=np.zeros((13,3,40)) #to be populated below\n",
    "\n",
    "for row,data in df_task_r.iterrows():\n",
    "    \n",
    "    if str(df_task_r['display'][row]).startswith('test'):\n",
    "        \n",
    "        if counter==0:\n",
    "            conditions.append(df_task_r['display'][row][5:])\n",
    "            condition_info=best_answer_key[conditions[counter]]\n",
    "            new_condition=0\n",
    "            counter+=1\n",
    "            \n",
    "\n",
    "        elif df_task_r['display'][row][5:]!=conditions[counter-1]:\n",
    "                    conditions.append(df_task_r['display'][row][5:])\n",
    "                    condition_info=best_answer_key[conditions[counter]]\n",
    "                    if conditions[counter-1]=='rare_threat_1':\n",
    "                        rt1.append(best_action_tally)\n",
    "                        rt_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='rare_threat_2':\n",
    "                        rt2.append(best_action_tally)\n",
    "                        rt_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='common_threat_1':\n",
    "                        ct1.append(best_action_tally)\n",
    "                        ct_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='common_threat_2':\n",
    "                        ct2.append(best_action_tally)\n",
    "                        ct_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='neutral_1':\n",
    "                        n1.append(best_action_tally)\n",
    "                        neut_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='neutral_2':\n",
    "                        n2.append(best_action_tally)\n",
    "                        neut_sub.append(current_choice_data)\n",
    "                    counter+=1\n",
    "                    best_action_tally=0\n",
    "                    current_choice_data=[]\n",
    "                    condition_counter+=1\n",
    "                    #after 6 blocks, new subject\n",
    "                    if condition_counter>5:\n",
    "                        current_subject+=1\n",
    "                        neut_sub=neut_sub[0]+neut_sub[1]\n",
    "                        if len(neut_sub)<40:\n",
    "                            neut_sub=[int(x) for x in neut_sub+np.zeros(40-len(neut_sub)).tolist()]\n",
    "             \n",
    "                            \n",
    "                        rt_sub=rt_sub[0]+rt_sub[1]\n",
    "                        if len(rt_sub)<40:\n",
    "                            rt_sub=[int(x) for x in rt_sub+np.zeros(40-len(rt_sub)).tolist()]\n",
    "                      \n",
    "                        ct_sub=ct_sub[0]+ct_sub[1]\n",
    "                        if len(ct_sub)<40:\n",
    "                            ct_sub=[int(x) for x in ct_sub+np.zeros(40-len(ct_sub)).tolist()]\n",
    "                        \n",
    "                        choice_data_3d[sub_counter,0]=neut_sub\n",
    "                        choice_data_3d[sub_counter,1]=ct_sub\n",
    "                        choice_data_3d[sub_counter,2]=rt_sub\n",
    "                        sub_counter+=1                                               \n",
    "                        condition_counter=0\n",
    "                        rt_sub=[]\n",
    "                        ct_sub=[]\n",
    "                        neut_sub=[]\n",
    "        \n",
    "        else:\n",
    "            new_condition=0\n",
    "                    \n",
    "        #Get values and convert from strings to floating point\n",
    "        value1=df_task_r['test_image1_value'][row]\n",
    "        if \"p\" in value1:\n",
    "            value1=float(value1[0:2])*0.01\n",
    "        else:\n",
    "            value1=float(value1[1])\n",
    "        value2=df_task_r['test_image2_value'][row]\n",
    "        if \"p\" in value2:\n",
    "            value2=float(value2[0:2])*0.01\n",
    "        else:\n",
    "            value2=float(value2[1])\n",
    "        \n",
    "        if value1>value2:\n",
    "            best_option=df_task_r['test_image1'][row]\n",
    "        else:\n",
    "            best_option=df_task_r['test_image2'][row]\n",
    "        \n",
    "            \n",
    "        #get response and convert to integer\n",
    "        try:\n",
    "            current_response=int(df_task_r['Response'][row])\n",
    "        except:\n",
    "            current_response='missing'\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        # determine if participant made best choice\n",
    "        for info_total in condition_info:\n",
    "            for info in info_total:\n",
    "                if best_option == str(info):\n",
    "                    best_action=info_total[0]\n",
    "\n",
    "        #for last subject only that doesn't meet the condition above for indexing     \n",
    "        if row==17254:\n",
    "            ct2.append(best_action_tally)\n",
    "            ct_sub.append(current_choice_data)\n",
    "            neut_sub=neut_sub[0]+neut_sub[1]\n",
    "            if len(neut_sub)<40:\n",
    "                neut_sub=[int(x) for x in neut_sub+np.zeros(40-len(neut_sub)).tolist()]\n",
    "\n",
    "\n",
    "            rt_sub=rt_sub[0]+rt_sub[1]\n",
    "            if len(rt_sub)<40:\n",
    "                rt_sub=[int(x) for x in rt_sub+np.zeros(40-len(rt_sub)).tolist()]\n",
    "\n",
    "            ct_sub=ct_sub[0]+ct_sub[1]\n",
    "            if len(ct_sub)<40:\n",
    "                ct_sub=[int(x) for x in ct_sub+np.zeros(40-len(ct_sub)).tolist()]\n",
    "\n",
    "            choice_data_3d[sub_counter,0]=neut_sub\n",
    "            choice_data_3d[sub_counter,1]=ct_sub\n",
    "            choice_data_3d[sub_counter,2]=rt_sub\n",
    "            sub_counter+=1                                               \n",
    "            condition_counter=0\n",
    "            rt_sub=[]\n",
    "            ct_sub=[]\n",
    "            neut_sub=[]\n",
    "\n",
    "        else:\n",
    "            if current_response==best_action:\n",
    "                best_action_tally+=1\n",
    "                current_choice_data.append(1.0)\n",
    "            elif current_response=='missing':\n",
    "                x='missing'\n",
    "            else:\n",
    "                current_choice_data.append(0.0)\n",
    "                \n",
    "\n",
    "#convert to numpy arrays    \n",
    "rt1=np.array(rt1)\n",
    "rt2=np.array(rt2)\n",
    "ct1=np.array(ct1)\n",
    "ct2=np.array(ct2)\n",
    "n1=np.array(n1)\n",
    "n2=np.array(n2)\n",
    "\n",
    "choice_data_3d = choice_data_3d.astype(int)\n",
    "print(choice_data_3d)\n",
    "np.save('choice_data_r1',choice_data_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Modelling pilot data hierarchically: explaining choice data\n",
    "\n",
    "In the present experiment, participants chose an action to obtain a reward based off a latent transition matrix they've presumably learned. The hypothesis is that this transition matrix is altered due to experimentally-manipulated features (valence of emotional distractors during learning) and person-specific factors that are not manipulated (level of chronic worry). \n",
    "\n",
    "We can conceive of the generative model of my data in the following way. We'll start from the bottom up. Each individual's decision is either a 1 or 0 (did they select the best-available option or not). The best-available option is the action that maximizes the EV according to a greedy policy (which is normative here given that learning has terminated once decision-making begins; that is, if I've learned I have a 60% chance pressing X will get me to the highest reward, and Y will get me there 40% of the time, I should always choose X). \n",
    "\n",
    "The $\\theta$ parameter determines a subjects' choice. If their bias is 0, it is an index that they're always choosing the worst action. If the bias is 1, they're maximizing performance. \n",
    "\n",
    "We use a Bernoulli likelihood to define the **subject-specific** data-generating process to explain their choice data:\n",
    "\n",
    "$Choice_{i,t}$ $\\sim$ Bernoulli$(\\theta_{i,k})$ Indices: i=subjects, t=trials, k=condition, where k(1) = neutral, k(2) = positive and k(3) = negative. \n",
    "\n",
    "These decicision biases, $\\theta$, vary by subject and condition. A subject specific factor, $\\eta_{i}$ reflects the baseline decision tendency to choose the best action. This is is modulated by the experimental condition $\\gamma_{k}$. A logistic link function is necessary to take a set spanning all values to the 0 to 1 range in order to be appropriate for the Bernoulli likelihood.\n",
    "\n",
    "$\\theta_{i,k}\\,= \\begin{cases}\n",
    "    \\text{logistic}\\, (\\eta_{i} + \\gamma_{1}),& \\text{if } k=1\\\\\n",
    "    \\text{logistic}\\,(\\eta_{i} + \\gamma_{2}),& \\text{if } k=2\\\\\n",
    "    \\text{logistic}\\,(\\eta_{i} + \\gamma_{3}),& \\text{if } k=3\\\\\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "$\\gamma_{1}$, $\\gamma_{2}$, and $\\gamma_{3}$ represent the biases for **each condition** modelled as a fixed effect, where each is drawn from **group-level distribution over condition effects**:\n",
    "\n",
    "$\\gamma_{1}$ $\\sim \\mathcal{N}(\\mu_{1},\\sigma_{1})$\n",
    "\n",
    "$\\gamma_{2}$ $\\sim \\mathcal{N}(\\mu_{2},\\sigma_{2})$\n",
    "\n",
    "$\\gamma_{3}$ $\\sim \\mathcal{N}(\\mu_{3},\\sigma_{3})$\n",
    "\n",
    "We also have a **subject-specific bias** drawn from the population distribution over biases. One can think of this as the tendency to learn well the state transitions in the present task necessary for good performance.\n",
    "\n",
    "$\\eta_i$ $\\sim$ $\\mathcal{G}(\\mathcal{S},\\mathcal{K})$\n",
    "\n",
    "Because we do not know *a priori* what the population-level distribution over each effect should be, we also need a prior distribution on these parameters. Priors over **subject effects** at the population level:\n",
    "\n",
    "Mean prior:\n",
    "$\\mathcal{S}\\sim\\mathcal{HalfCauchy}(0,1)$\n",
    "Variance prior:\n",
    "$\\mathcal{K}\\sim\\mathcal{HalfCauchy}(0,1)$\n",
    "\n",
    "The posterior joint distribution one is trying to estimate is: $p(\\gamma_{1,1}...\\gamma_{subject_i,condition_k},\\mu_{k},\\sigma_{k},\\mu_{i},\\sigma_{i}|data)$. Thus we must estimate $(i + k) + 5_{groupLevel})$ parameters, which for the present dataset, is a 21-dimensional distribution.We use pyStan to fit the model to the data below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build hierarchical model in pyStan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_094fef49eff134169ffff3bf7bc34866 NOW.\n",
      "WARNING:pystan:223 of 8000 iterations ended with a divergence (2.79 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_094fef49eff134169ffff3bf7bc34866.\n",
      "4 chains, each with iter=4000; warmup=2000; thin=1; \n",
      "post-warmup draws per chain=2000, total post-warmup draws=8000.\n",
      "\n",
      "                     mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "gamma_neutral       -1.14    0.06   0.53  -2.29  -1.47   -1.0  -0.73   -0.4     88   1.04\n",
      "gamma_positive      -2.87    0.06   0.55  -4.02  -3.23  -2.75  -2.45  -2.08     90   1.04\n",
      "gamma_negative      -2.76    0.06   0.54  -3.86  -3.13  -2.63  -2.35  -1.97     92   1.04\n",
      "k_subject            0.21  5.4e-3   0.11   0.05   0.13   0.19   0.27   0.46    398   1.01\n",
      "s_subject            1.06    0.04   0.49   0.34   0.69   0.98   1.35   2.19    147   1.02\n",
      "eta_subject[1]       1.92    0.06   0.56   1.03   1.49    1.8   2.29   3.07     99   1.04\n",
      "eta_subject[2]      14.19     0.3  16.77   6.72   9.21  11.68  15.76  37.37   3204    1.0\n",
      "eta_subject[3]       0.55    0.05    0.5 1.4e-3   0.14    0.4   0.87    1.7     94   1.04\n",
      "eta_subject[4]       4.12    0.05   0.58   3.17   3.69   4.03   4.53   5.31    112   1.04\n",
      "eta_subject[5]       1.83    0.06   0.56   0.98   1.41   1.73   2.21   2.99     98   1.04\n",
      "eta_subject[6]        4.5    0.06    0.6   3.53   4.05   4.41   4.93   5.74    108   1.04\n",
      "eta_subject[7]       5.92    0.06   0.75   4.62   5.38   5.85   6.41   7.54    145   1.03\n",
      "eta_subject[8]       0.65    0.06   0.54 1.7e-3    0.2   0.51    1.0   1.87     92   1.04\n",
      "eta_subject[9]      14.17    0.47  23.47   6.71   9.09  11.45  15.87  32.78   2485    1.0\n",
      "eta_subject[10]      5.16    0.06   0.65   4.07   4.67   5.07    5.6   6.42    114   1.04\n",
      "eta_subject[11]      0.64    0.06   0.54 4.1e-3   0.19    0.5   0.99   1.86     91   1.04\n",
      "eta_subject[12]     14.27    0.45  22.07   6.68    9.1   11.3   15.8  36.82   2403    1.0\n",
      "eta_subject[13]      6.28    0.06   0.81   4.87   5.67   6.21   6.83   7.92    169   1.02\n",
      "theta_neutral[1]     0.68  9.9e-4   0.05   0.58   0.65   0.69   0.72   0.78   2710    1.0\n",
      "theta_neutral[2]      1.0  1.4e-5 9.3e-4    1.0    1.0    1.0    1.0    1.0   4739    1.0\n",
      "theta_neutral[3]     0.36  9.3e-4   0.05   0.26   0.32   0.36    0.4   0.47   3391    1.0\n",
      "theta_neutral[4]     0.95  3.5e-4   0.01   0.92   0.94   0.95   0.96   0.97   1741    1.0\n",
      "theta_neutral[5]     0.67  7.7e-4   0.05   0.56   0.63   0.67    0.7   0.76   4487    1.0\n",
      "theta_neutral[6]     0.97  3.2e-4   0.01   0.94   0.96   0.97   0.97   0.98   1168    1.0\n",
      "theta_neutral[7]     0.99  2.6e-4 5.5e-3   0.98   0.99   0.99   0.99    1.0    430   1.01\n",
      "theta_neutral[8]     0.38  7.7e-4   0.06   0.27   0.34   0.38   0.42    0.5   5252    1.0\n",
      "theta_neutral[9]      1.0  2.5e-5 1.0e-3    1.0    1.0    1.0    1.0    1.0   1656    1.0\n",
      "theta_neutral[10]    0.98  1.3e-4 7.4e-3   0.96   0.98   0.98   0.99   0.99   3227    1.0\n",
      "theta_neutral[11]    0.38  7.9e-4   0.06   0.27   0.34   0.38   0.42   0.49   4869    1.0\n",
      "theta_neutral[12]     1.0  2.4e-5 9.4e-4    1.0    1.0    1.0    1.0    1.0   1475    1.0\n",
      "theta_neutral[13]    0.99  7.8e-5 4.2e-3   0.98   0.99   0.99    1.0    1.0   2916    1.0\n",
      "theta_positive[1]    0.28  7.8e-4   0.05   0.19   0.25   0.28   0.31   0.38   3619    1.0\n",
      "theta_positive[2]     1.0  7.5e-5 5.1e-3   0.98    1.0    1.0    1.0    1.0   4580    1.0\n",
      "theta_positive[3]    0.09  4.4e-4   0.02   0.05   0.08   0.09   0.11   0.14   2601    1.0\n",
      "theta_positive[4]    0.77  1.1e-3   0.05   0.67   0.74   0.78   0.81   0.86   1779    1.0\n",
      "theta_positive[5]    0.26  7.0e-4   0.05   0.18   0.23   0.26    0.3   0.36   4291    1.0\n",
      "theta_positive[6]    0.83  1.4e-3   0.04   0.74   0.81   0.84   0.86   0.91    900   1.01\n",
      "theta_positive[7]    0.95  1.4e-3   0.03   0.88   0.93   0.95   0.97   0.99    369   1.01\n",
      "theta_positive[8]     0.1  3.5e-4   0.02   0.06   0.08    0.1   0.11   0.15   4578    1.0\n",
      "theta_positive[9]     1.0  1.2e-4 5.3e-3   0.98    1.0    1.0    1.0    1.0   2075    1.0\n",
      "theta_positive[10]    0.9  5.2e-4   0.03   0.83   0.88   0.91   0.93   0.96   3782    1.0\n",
      "theta_positive[11]    0.1  3.7e-4   0.02   0.06   0.08    0.1   0.11   0.15   4154    1.0\n",
      "theta_positive[12]    1.0  1.5e-4 5.2e-3   0.98    1.0    1.0    1.0    1.0   1260    1.0\n",
      "theta_positive[13]   0.96  3.8e-4   0.02   0.91   0.95   0.97   0.98   0.99   3120    1.0\n",
      "theta_negative[1]     0.3  7.1e-4   0.05   0.21   0.27    0.3   0.33    0.4   4661    1.0\n",
      "theta_negative[2]     1.0  6.9e-5 4.7e-3   0.98    1.0    1.0    1.0    1.0   4664    1.0\n",
      "theta_negative[3]     0.1  4.4e-4   0.02   0.06   0.08    0.1   0.12   0.16   3088    1.0\n",
      "theta_negative[4]    0.79  7.9e-4   0.04    0.7   0.76   0.79   0.82   0.87   3135    1.0\n",
      "theta_negative[5]    0.29  7.1e-4   0.05    0.2   0.25   0.28   0.32   0.38   4508    1.0\n",
      "theta_negative[6]    0.85  8.2e-4   0.04   0.76   0.82   0.85   0.87   0.91   2238    1.0\n",
      "theta_negative[7]    0.95  1.1e-3   0.02    0.9   0.94   0.96   0.97   0.99    491   1.01\n",
      "theta_negative[8]    0.11  3.8e-4   0.03   0.07   0.09   0.11   0.13   0.17   4834    1.0\n",
      "theta_negative[9]     1.0  1.1e-4 4.8e-3   0.98    1.0    1.0    1.0    1.0   1999    1.0\n",
      "theta_negative[10]   0.91  5.5e-4   0.03   0.84   0.89   0.92   0.93   0.96   2941    1.0\n",
      "theta_negative[11]   0.11  4.1e-4   0.03   0.07   0.09   0.11   0.13   0.17   3911    1.0\n",
      "theta_negative[12]    1.0  1.0e-4 4.6e-3   0.98    1.0    1.0    1.0    1.0   1953    1.0\n",
      "theta_negative[13]   0.97  3.6e-4   0.02   0.92   0.96   0.97   0.98   0.99   2812    1.0\n",
      "lp__               -478.9    0.34   4.86 -489.4 -482.0 -478.4 -475.3 -470.7    201   1.02\n",
      "\n",
      "Samples were drawn using NUTS at Sat Sep 21 13:15:08 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "from pystan import StanModel\n",
    "\n",
    "\n",
    "model_input='''\n",
    "data {\n",
    "    int<lower=0> N;      // # of subjects\n",
    "    int N_cond;\n",
    "    int T_max;  // max # of trials across subjects\n",
    "    int Choice[N, N_cond, T_max]; // Choices for each subject, condition, and trial\n",
    "}\n",
    "\n",
    "parameters {  \n",
    " \n",
    "  // Parameters for group-level parameters\n",
    "  // Experimental Effects\n",
    "  real gamma_neutral;\n",
    "  real gamma_positive;\n",
    "  real gamma_negative;\n",
    "  \n",
    "  //Baseline Effects\n",
    "  real<lower=0> k_subject;\n",
    "  real<lower=0> s_subject;\n",
    "  \n",
    "  // Individual-level parameters\n",
    "  real<lower=0> eta_subject[N];\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  vector[N] theta_neutral;\n",
    "  vector[N] theta_positive;\n",
    "  vector[N] theta_negative;\n",
    "\n",
    "  // For all subjects, incorporate baseline and experimental effect, \n",
    "  // then convert to 0-1 scale via logistic function. \n",
    "  \n",
    "  for (i in 1:N) {\n",
    "    theta_neutral[i] = inv_logit(eta_subject[i]+gamma_neutral[i]);\n",
    "    theta_positive[i] = inv_logit(eta_subject[i]+gamma_positive[i]);\n",
    "    theta_negative[i] = inv_logit(eta_subject[i]+gamma_negative[i]);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  // Priors on group-level fixed effects\n",
    " \n",
    "  \n",
    "  //Baseline Effects\n",
    "  s_subject ~ normal(0,1);\n",
    "  k_subject ~ normal(0,1);\n",
    "\n",
    "  \n",
    "  // Priors on individual parameters\n",
    "  eta_subject ~ gamma(s_subject,k_subject);\n",
    "\n",
    "    \n",
    "  // Generate data for each subject via Bernoulli likelihood\n",
    "  for (i in 1:N) {\n",
    "  \n",
    "  \n",
    "     gamma_neutral[i] ~ normal(0,10);\n",
    "     gamma_positive[i] ~ normal(0,10);\n",
    "     gamma_negative[i] ~ normal(0,10);\n",
    "    // Neutral condition choices\n",
    "    Choice[i,1,:] ~ bernoulli(theta_neutral[i]);\n",
    "    // Positive condition choices\n",
    "    Choice[i,2,:] ~ bernoulli(theta_positive[i]);\n",
    "    // Negative condition choices\n",
    "    Choice[i,3,:] ~ bernoulli(theta_negative[i]);    \n",
    "  }\n",
    "}\n",
    "\n",
    "'''\n",
    "data_input = {'N': 13, #subjects\n",
    "                     'N_cond': 3, # conditions\n",
    "                     'T_max': 40, # trials per condition\n",
    "                     'Choice':choice_data_3d #choice data in a 3d Vector\n",
    "                    }\n",
    "\n",
    "# controls={}\n",
    "# controls['adapt_delta']=0.8\n",
    "\n",
    "model_fit = StanModel(model_code=model_input)\n",
    "fit = model_fit.sampling(data=data_input,iter=4000)\n",
    "print(fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
